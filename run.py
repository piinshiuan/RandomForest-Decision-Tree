# -*- coding: utf-8 -*-
"""0713412_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o5A7eWPXNdB5gROQR8gcnGpCAhJMo0nA

# Assignment 2: Decision Trees

In this assignment, you are going to implement a decision tree (or random forest) to forcast the weather.

## Description

- You must implement a `Model` class for training and prediction:
  ```python
  X, y = load_dataset()

  model = Model(num_features, num_classes)

  # training
  model.fit(X, y)

  # prediction
  y_pred = model.predict(X)
  ```
- Please search (Ctrl+F) for `TODO` to see what you need to do. You have to implement the classifier from scratch (do not directly use the classifier in scikit-learn).
- About the dataset
  - Given the **training set**, please **train/validate** on it.  
  (note that your model will get bad testing score if it overfits on the training set)
  - After submitting the assignment, we will train on the same training set and test on the hidden **testing set** for scoring (using [f1-score](https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec#11b8)).

### Typical performance

- **Random Guess**  
  F1-Score: 0.30  
  Accuracy: 0.50
- **Always Predict 1**  
  F1-Score: 0.37  
  Accuracy: 0.22
- **Always Predict 0**  
  F1-Score: 0.00  
  Accuracy: 0.77
- **sklearn.tree.DecisionTreeClassifier**  
  - **Training (5-fold cross-validation mean)**  
    F1-Score: 0.63-0.99  
    Accuracy: 0.85-0.99
  - **Validation (5-fold cross-validation mean)**  
    F1-Score: 0.50-0.60  
    Accuracy: 0.75-0.90
"""

###########################
# DO NOT CHANGE THIS CELL #
###########################

import os
import urllib.request
import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.metrics import f1_score, accuracy_score


def load_dataset(url):
  """ Get and load weather dataset. """

  path = url.split('/')[-1] # get the file name from url

  if not os.path.exists(path):
    print('Download:', url)
    urllib.request.urlretrieve(url, path)

  return pd.read_pickle(path) # pickle protocol=4


def get_input_target(df):
  """ Get X and y from weather dataset. """
  
  target_column = 'RainTomorrow' # predict 1 of it rains tomorrow

  X = df.drop(columns=[target_column]).to_numpy()
  y = df[target_column].to_numpy()

  return X, y


def k_fold_cv(model_create_fn, X, y, k=5):
  """ Run k-fold cross-validation. """

  results = []

  idxs = list(range(X.shape[0]))
  np.random.shuffle(idxs)

  for i, (train_idxs, val_idxs) in enumerate(KFold(k).split(idxs)):
    splits = {'train': (X[train_idxs], y[train_idxs]),
              'val':   (X[val_idxs],   y[val_idxs]  )}

    print('Run {}:'.format(i+1))

    model = model_create_fn()
    start = time.time()
    model.fit(*splits['train']) # training
    print('Fit: {time}s'.format(time=time.time() - start,))
    for name, (X_split, y_split) in splits.items():
      start = time.time()
      y_pred = model.predict(X_split)
      print('{name}: {time}s'.format(time=time.time() - start,name=name))
      result = {'split': name,
                'f1': f1_score(y_pred, y_split), #(prdict結果，正確結果)
                'acc': accuracy_score(y_pred, y_split)}
      results.append(result)

      print('{split:>8s}: f1={f1:.4f} acc={acc:.4f}'.format(**result))

  return pd.DataFrame(results)

import time
# @begin

# TODO: you can define or import something here (optional)
import copy

class Node:
  def __init__(self,data=None,feature=None,value=None,Left=None,Right=None,guess=None,rule=None,depth=None):
    self.data=data
    self.feature=feature
    self.value=value
    self.Left=Left
    self.Right=Right
    self.guess=guess
    self.rule=rule
    self.depth=depth

#將資料集依照feature限制分開來
"""
def SplitDataSet(dataSet, feature, value):  
  Right = dataSet[np.nonzero(dataSet[:,feature] > value)]
  Left = dataSet[np.nonzero(dataSet[:,feature] <= value)]    
  return Left,Right
"""

def SplitDataSet(dataSet, feature, value):

    ge_thresh = dataSet[:,feature] > value
    
    left = dataSet[~ge_thresh]
    right = dataSet[ge_thresh]
    
    return left, right

#要計算gini值之dataset的answer
def gini(dataSet):
  #看answer在哪一行
  #print(dataSet)
  answer=len(dataSet[0])-1
  uniquefeature=np.unique(dataSet[:,answer])
  f=[]
  for feature in uniquefeature:
    #append the feature count in a count list
    f.append(np.count_nonzero(dataSet[:,answer] == feature))
  gini=1
  for count in f:
    gini-=(float(count/sum(f)))**2
  return gini

#選擇讓gini值最小的分裂點
def ComputeBestFeatureCut(dataSet,feature):
  dataSet = dataSet[dataSet[:,feature].argsort()]
  unique=np.unique(dataSet[:,feature])
  mingini={}
  if len(unique)==1:
    return -1
  for i in range(len(unique)-1):
    cut=unique[i]
    left=dataSet[dataSet[:,feature] <= cut]
    right=dataSet[dataSet[:,feature] > cut]
    total=len(left)+len(right)
    gi=((len(left)/total)*gini(left))+((len(right)/total)*gini(right))
    mingini[cut]=gi
  cutvalue=min(mingini, key=lambda k: mingini[k]) 
  return cutvalue



def chosefeature(dataSet):
  chose={}
  for feature in range(len(dataSet[0])-2):
    dataSet = dataSet[dataSet[:,feature].argsort()]
    unique=np.unique(dataSet[:,feature])
    mingini={}
    if len(unique)==1:
      #chose[feature]=[-1,100]
      continue
    for i in range(len(unique)-1):
      cut=unique[i]
      left=dataSet[dataSet[:,feature] <= cut]
      right=dataSet[dataSet[:,feature] > cut]
      total=len(left)+len(right)
      gi=((len(left)/total)*gini(left))+((len(right)/total)*gini(right))
      mingini[cut]=gi
    cutvalue=min(mingini, key=lambda k: mingini[k])#arg
    chose[feature]=[cutvalue,mingini[cutvalue]]
  chosefeature=min(chose, key=lambda k: chose[k][1])#arg
  cutvalue=chose[chosefeature][0]
  return chosefeature,cutvalue

def guess(dataset):
  f={}
  uniquefeature=np.unique(dataset[:,len(dataset[0])-1])
  for feature in uniquefeature:
    #append the feature count in a count list
    f[feature]=np.count_nonzero(dataset[:,len(dataset[0])-1] == feature)
  guess= max(f.keys(), key=(lambda k: f[k]))
  return guess 

leaf=0 
def decisiontree(now):
  global leaf
  #如果data集已經很小了或是全部都是同一分類
  if now.depth==10 or len(np.unique(now.data[:,len(now.data[0])-1]))==1:
    leaf+=1
    now.guess=guess(now.data)
    now.data=0
    return
  #now.feature=chosefeature(now.data)
  feature,cut=chosefeature(now.data)
  #print(feature)
  now.feature=feature
  now.value=cut
  if cut==-1:
    leaf+=1
    now.guess=guess(now.data)
    now.data=0
    return
  Leftdata,Rightdata=SplitDataSet(now.data, now.feature, now.value)
  Left=Node(Leftdata,depth=now.depth+1)
  Right=Node(Rightdata,depth=now.depth+1)
  #更新now node的值
  #now.rule[feature]=value
  now.Left=Left
  now.Right=Right
  now.data=0
  return decisiontree(Left),decisiontree(Right)

def saveTree(tree):
    decisionTree= deepcopy(tree)
    pickle.dump(decisionTree,open('model.pkl','wb'))


def classify(tree,data):
  if tree.value==None:
    return tree.guess
  if data[tree.feature]<=tree.value:
    return classify(tree.Left,data)
  else:
    return classify(tree.Right,data)
    
class Model:

  def __init__(self, num_features: int, num_classes: int):
    """
    Initialize the model.

    Args:
        num_features (int) : the input feature size.15個特徵值
        num_classes (int) : number of output classes.0 or 1
    """

    self.num_features = num_features
    self.num_classes = num_classes
    self.start=Node()

    # TODO: implement your model initialization here (optional)



  def fit(self, X: np.ndarray, y: np.ndarray):

    """
    Train on input/target pairs.

    Args:
        X (np.ndarray) : training inputs with shape (num_inputs, num_features).
        y (np.ndarray) : training targets with shape (num_inputs,).
    """
    global leaf
    # TODO: implement your training algorithm here
    #所有特徵值皆為離散分佈
    #每個特徵輪流剪
    y=y.reshape(y.shape[0],1)
    Xy=np.append(X,y, axis=1)
    
    
    now=Node(Xy,feature=0,depth=0)
    decisiontree(now)
    print("leaf: {}".format(leaf))
    self.start=copy.deepcopy(now)
    

  def predict(self, X: np.ndarray) -> np.ndarray:
    '''
    Predict y given X.

    Args:
        X (np.ndarray) : inputs, shape: (num_inputs, num_features).
    
    Returns:
        np.ndarray : the predicted integer outputs, shape: (num_inputs,).
    '''

    # TODO: implement your prediction algorithm here
    #p = np.random.randint(0, self.num_classes, size=X.shape[0]) # (delete this)

    p=[]
    now=copy.deepcopy(self.start)
    start = time.time()
    for i in range(len(X)):
      p.append(classify(now,X[i]))
    print('classify time: {}'.format(time.time() - start))
    p=np.array(p)
    print(p)
    return p

  # TODO: define your methods if needed (optional)

# @end

###########################
# DO NOT CHANGE THIS CELL #
###########################

df = load_dataset('https://lab.djosix.com/weather.pkl')
X_train, y_train = get_input_target(df)# train是訓練集 x是訓練資料 y是標籤(答案)
print(len(X_train))
#print(X_train)
#print(len(X_train[0]))

#看資料樣子
#print(df.head(10))#預設show出五筆資料

###########################
# DO NOT CHANGE THIS CELL #
###########################

create_model = lambda: Model(X_train.shape[1], 2)

model=create_model()
print(sum(y_train)/len(y_train))
x=X_train[:10000]
y= y_train[:10000]
start = time.time()
model.fit(x,y) # training

print('fit time: {}'.format(time.time() - start))
#start = time.time()
X_split=X_train[20000:21000]
y_split=y_train[20000:21000]
y_pred = model.predict(X_split)
result = {'split': "test",
          'f1': f1_score(y_pred, y_split), #(prdict結果，正確結果)
          'acc': accuracy_score(y_pred, y_split)}

print(result)
#print('predict time: {}'.format(time.time() - start))


#k_fold_cv(create_model, X_train, y_train).groupby('split').mean()# run k fold cross validation

"""## Submission

1. Make sure your code runs correctly after clicking `"Runtime" > "Restart and run all"`
2. Rename this notebook to `XXXXXXX_2.ipynb`, where `XXXXXXX` is your student ID.
3. Download IPython notebook: `"File" > "Download" > "Download .ipynb"`
4. Download Python source code: `"File" > "Download" > "Download .py"`
5. Create a zip file for `XXXXXXX_2.ipynb` and `XXXXXXX_2.py`  
   named `XXXXXXX_2.zip`, where `XXXXXXX` is your student ID.
6. Upload the zip file to E3.

😊 Good luck!
"""